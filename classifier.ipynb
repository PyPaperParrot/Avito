{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:10:31.663816Z",
     "start_time": "2019-05-06T20:10:31.440437Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:10:36.710610Z",
     "start_time": "2019-05-06T20:10:32.202102Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('new_transformed_data.csv', usecols = ['lemmatized_text', 'category_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:10:37.832238Z",
     "start_time": "2019-05-06T20:10:37.799642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>картина гобелен размер х сантиметр</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>стул прессовать кожа продать недорого стул све...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>домашний минь баня минь баня мб минь сауна пре...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>эксклюзивный коллекция книга трансаэро подарок...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ноутбук aser продаваться ноутбук acer e c ta к...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id                                    lemmatized_text\n",
       "0           19                 картина гобелен размер х сантиметр\n",
       "1           22  стул прессовать кожа продать недорого стул све...\n",
       "2           37  домашний минь баня минь баня мб минь сауна пре...\n",
       "3           43  эксклюзивный коллекция книга трансаэро подарок...\n",
       "4            1  ноутбук aser продаваться ноутбук acer e c ta к..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:11:16.488366Z",
     "start_time": "2019-05-06T20:10:46.426602Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import textblob, string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:11:24.429665Z",
     "start_time": "2019-05-06T20:11:24.208318Z"
    }
   },
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(data['lemmatized_text'], data['category_id'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is the feature engineering step. In this step, raw text data will be transformed into feature vectors and new features will be created using the existing dataset. We will implement the following ideas in order to obtain relevant features from our dataset.\n",
    "\n",
    "+ 2.1 Count Vectors as features\n",
    "+ 2.2 TF-IDF Vectors as features\n",
    "\n",
    "+ + Word level\n",
    "\n",
    "\n",
    "Lets look at the implementation of these ideas in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Count Vectors as features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T15:49:23.841535Z",
     "start_time": "2019-05-03T15:48:33.980424Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(data['lemmatized_text'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T15:49:29.897135Z",
     "start_time": "2019-05-03T15:49:29.869734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<367137x314380 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9506395 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 TF-IDF Vectors as features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:11:53.745116Z",
     "start_time": "2019-05-06T20:11:29.203352Z"
    }
   },
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=9000)\n",
    "tfidf_vect.fit(data['lemmatized_text'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:11:54.395179Z",
     "start_time": "2019-05-06T20:11:54.385604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<391613x9000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 8950148 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Building\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step in the text classification framework is to train a classifier using the features created in the previous step. There are many different choices of machine learning models which can be used to train a final model. We will implement following different classifiers for this purpose:\n",
    "\n",
    "+ Naive Bayes Classifier\n",
    "+ Bagging Models\n",
    "+ SGD Classifier\n",
    "\n",
    "Lets implement these models and understand their details. The following function is a utility function which can be used to train a model. It accepts the classifier, feature_vector of training data, labels of training data and feature vectors of valid data as inputs. Using these inputs, the model is trained and accuracy score is computed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:12:03.090681Z",
     "start_time": "2019-05-06T20:12:03.075801Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    %time\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T16:08:14.286889Z",
     "start_time": "2019-05-06T16:08:13.608394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 0 ns, total: 9 µs\n",
      "Wall time: 17.9 µs\n",
      "NB, WordLevel TF-IDF:  0.8465844092171924\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"NB, WordLevel TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "NB, WordLevel TF-IDF:  0.8264830854714823\n",
    "\n",
    "\n",
    "NB, Count Vectors:  0.8550825298251348"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Bagging Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:41:16.379002Z",
     "start_time": "2019-05-06T20:25:32.842547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 10.5 µs\n",
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 8.58 µs\n",
      "RF, WordLevel TF-IDF:  0.8302214414119954\n"
     ]
    }
   ],
   "source": [
    "# RF on Word Level TF IDF Vectors with maxfeatures 9000\n",
    "%time\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(n_estimators=25), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"RF, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "#было 0.8033583918941003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 SGD Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:25:01.207935Z",
     "start_time": "2019-05-06T20:25:01.200552Z"
    }
   },
   "outputs": [],
   "source": [
    "sgd_cls = linear_model.SGDClassifier(alpha=0.000001, random_state=0, class_weight='balanced', penalty='l2', loss='log', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:25:17.273534Z",
     "start_time": "2019-05-06T20:25:01.952272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 µs, sys: 1e+03 ns, total: 14 µs\n",
      "Wall time: 26.2 µs\n",
      "sgd, WordLevel TF-IDF:  0.8707509396960288\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(sgd_cls, xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"sgd, WordLevel TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:49:53.864803Z",
     "start_time": "2019-05-06T20:49:52.429687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>489517</td>\n",
       "      <td>Стоик журнальный сталь</td>\n",
       "      <td>продам журнальный столик изготавливаю столы из...</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489518</td>\n",
       "      <td>iPhone 5 64Gb</td>\n",
       "      <td>Телефон в хорошем состоянии. Комплект, гаранти...</td>\n",
       "      <td>12500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>489519</td>\n",
       "      <td>Утеплитель</td>\n",
       "      <td>ТЕПЛОПЕЛЕН-ЛИДЕР ТЕПЛА!!! Толщина утеплителя :...</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>489520</td>\n",
       "      <td>Пальто демисезонное</td>\n",
       "      <td>Продам пальто женское (букле) в отличном состо...</td>\n",
       "      <td>1700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>489521</td>\n",
       "      <td>Samsung syncmaster T200N</td>\n",
       "      <td>Условно рабочий, проблема в панели настройки м...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                     title  \\\n",
       "0   489517    Стоик журнальный сталь   \n",
       "1   489518             iPhone 5 64Gb   \n",
       "2   489519                Утеплитель   \n",
       "3   489520       Пальто демисезонное   \n",
       "4   489521  Samsung syncmaster T200N   \n",
       "\n",
       "                                         description    price  \n",
       "0  продам журнальный столик изготавливаю столы из...  10000.0  \n",
       "1  Телефон в хорошем состоянии. Комплект, гаранти...  12500.0  \n",
       "2  ТЕПЛОПЕЛЕН-ЛИДЕР ТЕПЛА!!! Толщина утеплителя :...    250.0  \n",
       "3  Продам пальто женское (букле) в отличном состо...   1700.0  \n",
       "4  Условно рабочий, проблема в панели настройки м...   1000.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('test.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:50:01.433494Z",
     "start_time": "2019-05-06T20:50:01.418029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(243166, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:50:22.291267Z",
     "start_time": "2019-05-06T20:50:18.043850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>text</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>489517</td>\n",
       "      <td>Стоик журнальный сталь продам журнальный столи...</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489518</td>\n",
       "      <td>iPhone 5 64Gb Телефон в хорошем состоянии. Ком...</td>\n",
       "      <td>12500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>489519</td>\n",
       "      <td>Утеплитель ТЕПЛОПЕЛЕН-ЛИДЕР ТЕПЛА!!! Толщина у...</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>489520</td>\n",
       "      <td>Пальто демисезонное Продам пальто женское (бук...</td>\n",
       "      <td>1700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>489521</td>\n",
       "      <td>Samsung syncmaster T200N Условно рабочий, проб...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                                               text    price\n",
       "0   489517  Стоик журнальный сталь продам журнальный столи...  10000.0\n",
       "1   489518  iPhone 5 64Gb Телефон в хорошем состоянии. Ком...  12500.0\n",
       "2   489519  Утеплитель ТЕПЛОПЕЛЕН-ЛИДЕР ТЕПЛА!!! Толщина у...    250.0\n",
       "3   489520  Пальто демисезонное Продам пальто женское (бук...   1700.0\n",
       "4   489521  Samsung syncmaster T200N Условно рабочий, проб...   1000.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.insert(1 , 'text', data.apply(lambda x: x['title'] + ' ' + x['description'], axis=1))\n",
    "data.drop(['title', 'description'], axis=1, inplace=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:50:40.242185Z",
     "start_time": "2019-05-06T20:50:40.236830Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#Let's use 'GOOD OLD'regular expressions for cleanup and standard func '.lower()' to make words similar\n",
    "def del_symb(text):\n",
    "    #return re.sub(r\"[^a-zA-Zа-яёА-Я0-9]\", \" \", text.lower())\n",
    "    return re.sub(r\"[^a-zA-Zа-яёА-Я]\", \" \", text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:50:56.222086Z",
     "start_time": "2019-05-06T20:50:51.946885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>text</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>489517</td>\n",
       "      <td>стоик журнальный сталь продам журнальный столи...</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489518</td>\n",
       "      <td>iphone     gb телефон в хорошем состоянии  ком...</td>\n",
       "      <td>12500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>489519</td>\n",
       "      <td>утеплитель теплопелен лидер тепла    толщина у...</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>489520</td>\n",
       "      <td>пальто демисезонное продам пальто женское  бук...</td>\n",
       "      <td>1700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>489521</td>\n",
       "      <td>samsung syncmaster t   n условно рабочий  проб...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                                               text    price\n",
       "0   489517  стоик журнальный сталь продам журнальный столи...  10000.0\n",
       "1   489518  iphone     gb телефон в хорошем состоянии  ком...  12500.0\n",
       "2   489519  утеплитель теплопелен лидер тепла    толщина у...    250.0\n",
       "3   489520  пальто демисезонное продам пальто женское  бук...   1700.0\n",
       "4   489521  samsung syncmaster t   n условно рабочий  проб...   1000.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data['text'].apply(del_symb)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:51:18.734432Z",
     "start_time": "2019-05-06T20:51:18.714940Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import Stemmer as stm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:51:32.630959Z",
     "start_time": "2019-05-06T20:51:32.619708Z"
    }
   },
   "outputs": [],
   "source": [
    "def process(input_text):\n",
    "    language = 'russian'\n",
    "    #stemmer = stm.Stemmer(language)\n",
    "    \n",
    "    # List of stop words \n",
    "    stop_words = stopwords.words(language)\n",
    "    # Remove the stop words \n",
    "    input_text = [x for x in input_text.split() if not x in stop_words]  \n",
    "    # Stemming on the words \n",
    "    #input_text = [stemmer.stemWord(x) for x in input_text]\n",
    "    \n",
    "    return ' '.join(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:52:19.948332Z",
     "start_time": "2019-05-06T20:51:44.075828Z"
    }
   },
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:52:31.287943Z",
     "start_time": "2019-05-06T20:52:31.271364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>text</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>489517</td>\n",
       "      <td>стоик журнальный сталь продам журнальный столи...</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489518</td>\n",
       "      <td>iphone gb телефон хорошем состоянии комплект г...</td>\n",
       "      <td>12500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>489519</td>\n",
       "      <td>утеплитель теплопелен лидер тепла толщина утеп...</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>489520</td>\n",
       "      <td>пальто демисезонное продам пальто женское букл...</td>\n",
       "      <td>1700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>489521</td>\n",
       "      <td>samsung syncmaster t n условно рабочий проблем...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                                               text    price\n",
       "0   489517  стоик журнальный сталь продам журнальный столи...  10000.0\n",
       "1   489518  iphone gb телефон хорошем состоянии комплект г...  12500.0\n",
       "2   489519  утеплитель теплопелен лидер тепла толщина утеп...    250.0\n",
       "3   489520  пальто демисезонное продам пальто женское букл...   1700.0\n",
       "4   489521  samsung syncmaster t n условно рабочий проблем...   1000.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:52:59.301548Z",
     "start_time": "2019-05-06T20:52:59.292179Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "from pymorphy2 import MorphAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-06T20:53:08.905347Z",
     "start_time": "2019-05-06T20:53:08.888829Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_lemmatize1(df):\n",
    "    lemmatizer = MorphAnalyzer()\n",
    "    lemm_func = lambda text: ' '.join([lemmatizer.normal_forms(word)[0] for word in text.split()])\n",
    "    df['lemmatized_text'] = df['text'].apply(lemm_func)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-06T20:53:23.480Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data = to_lemmatize1(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=9000)\n",
    "tfidf_vect.fit(data['lemmatized_text'])\n",
    "xtest_tfidf =  tfidf_vect.transform(data['lemmatized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = sgd_cls.predict(xtest_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pd.Series(test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
